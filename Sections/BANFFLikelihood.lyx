#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
% ams math packages
\usepackage[cmex10]{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

% graphics packages
\usepackage{graphicx} % remove pdftex if you are not compiling to pdf
%\graphicspath{{./figures/}} % this places all graphics in the figures subdirectory

% allowed graphics extensions
% uncomment if you prefer to add extension in \includegraphics
\DeclareGraphicsExtensions{.pdf,.png,.jpg}

% allows the creation of subfigures
\usepackage[caption=false]{subfig}

% book tables are simple and look nice
\usepackage{booktabs}

% for specifying urls and links
\usepackage{url}
\urlstyle{same} % same style as regular text

% for defining colors
\usepackage{xcolor}

%\usepackage[labelformat=empty]{caption}
%\usepackage{subcaption}
\usepackage{lmodern}
\usepackage{csquotes}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{hepunits}
\usepackage{hepnames}
\usepackage{physics}

\usepackage[%
  pdfpagelabels,
  pdfusetitle,
  %hidelinks,
  %colorlinks=true,
  %pdfborder={0 0 0},
  linkcolor=blue,
  filecolor=magenta,
  urlcolor=cyan,
  pagebackref,
  bookmarksopen,
  bookmarksnumbered]{hyperref}

\usepackage{sectsty}
\chapterfont{\centering}

\usepackage{braket}
\end_preamble
\use_default_options true
\master ../TN.lyx
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "palatino" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format pdf2
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\pdf_title "HoganThesis"
\pdf_author "Matthew Hogan"
\pdf_bookmarks true
\pdf_bookmarksnumbered true
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\papersize letterpaper
\use_geometry true
\use_package amsmath 0
\use_package amssymb 0
\use_package cancel 0
\use_package esint 0
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\branch Introduction
\selected 1
\filename_suffix 0
\color #faf0e6
\end_branch
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Subsection
BANFF Treatment of ND Constraint
\end_layout

\begin_layout Standard
The BANFF implementation aims to reduce the dimensionality, and hence complexity
, of the joint near detector (ND) and far detector (FD) problem by performing
 a separate analysis on the nuisance parameters that only the ND can measure.
 In a joint ND and FD joint fit, the measurements from both detectors are
 considered along with their respective systematic uncertainties.
 This approach is computationally expensive since the time to perform a
 fit increases non-linearly with dimensionality.
 BANFF considers a ND-only fit in order to decrease the computational demands.
 The BANFF post-fit parameters and their covariances are then propagated
 to the oscillation analysis using FD-only data.
 This allows for more rapidly completed studies on the effects of model
 parameters and biases present.
 Conceptually this approach should provide the same result with a joint
 ND and FD analysis.
 However, information encoded in the ND measurements for shared nuisance
 parameters is inevitably lost in this 
\begin_inset Quotes eld
\end_inset

divide-and-conquer
\begin_inset Quotes erd
\end_inset

 approach.
\end_layout

\begin_layout Standard
The BANFF ND-only constraint between 2015 through 2018 is described in detail
 in TN-220
\begin_inset CommandInset citation
LatexCommand citet
key "Hartz2015"
literal "false"

\end_inset

.
 While subsequent updates to the BANFF analysis increase the sample sizes
 and systematic parameterizations, the method has remained unchanged.
 It uses a frequentist approach to find the best nuisance parameter set
 to maximize a binned likelihood.
\end_layout

\begin_layout Subsubsection
Likelihood Functions
\end_layout

\begin_layout Standard
Consider the problem of extracting physics parameters 
\begin_inset Formula $\vec{y}$
\end_inset

 given some data 
\begin_inset Formula $\vec{N}$
\end_inset

.
 The probability 
\begin_inset Formula $\mathcal{P}$
\end_inset

 to measure these parameters is given as
\begin_inset Formula 
\begin{equation}
\prob{\vec{y}\left|\vec{N}\right.}=\frac{\mathcal{L}\left(\left.\vec{N}\right|\vec{y}\right)\pi\left(\vec{y}\right)}{\int\mathcal{L}\left(\left.\vec{N}\right|\vec{y}\right)\pi\left(\vec{y}\right)d\vec{y}},\label{eq:likelihoodgeneral}
\end{equation}

\end_inset

where 
\begin_inset Formula $\mathcal{L}\left(\left.\vec{N}\right|\vec{y}\right)$
\end_inset

 is the likelihood of the parameters, 
\begin_inset Formula $\pi(\vec{y})$
\end_inset

 are priors on the 
\begin_inset Formula $\vec{y}$
\end_inset

 terms, and the denominator is the normalization.
 One arrives at 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:likelihoodgeneral"
plural "false"
caps "false"
noprefix "false"

\end_inset

 by using Bayes' theorem
\begin_inset Formula 
\begin{equation}
\prob{AB}=\prob B\prob{A\left|B\right.}\label{eq:bayestheorem}
\end{equation}

\end_inset

to evaluate 
\begin_inset Formula $\prob{\vec{y}\left|\vec{N}\right.}$
\end_inset

 as
\begin_inset Formula 
\begin{equation}
\prob{\underset{A}{\underbrace{\vec{y}}}\left|\underset{B}{\underbrace{\vec{N}}}\right.}=\frac{\prob{\vec{N},\vec{y}}}{\prob{\vec{N}}}.\label{eq:bayes1}
\end{equation}

\end_inset

with the demoninator here is recognized as the normalization.
 Since the data measurements are independent of the nuisance parameters,
 Bayes' theorem can be applied again on the numerator in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:bayes1"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\begin_inset Formula 
\begin{equation}
\prob{\underset{A}{\underbrace{\vec{y}}},\underset{B}{\underbrace{\vec{N}}}}=\prob{\left.\vec{N}\right|\vec{y}}\times\prob{\vec{y}},\label{eq:bayes2}
\end{equation}

\end_inset

where the PDFs to the left and right of the 
\begin_inset Formula $\times$
\end_inset

 operator are recognized as the likelihoods and priors, respectively.
 Combining resulting in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:bayes1"
plural "false"
caps "false"
noprefix "false"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:bayes2"
plural "false"
caps "false"
noprefix "false"

\end_inset

 reproduces the original expression of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:likelihoodgeneral"
plural "false"
caps "true"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection
BANFF Likelihood and Test Statistic
\end_layout

\begin_layout Standard
For the BANFF fit, one considers the problem of trying to maximize the agreement
 between measured and predicted data histrograms.
 This is equivalent to maximizing a binned likelihood function 
\begin_inset Formula $\mathcal{L}$
\end_inset

 of the data given the a set of parameters that predict the measured rate.
 The use of likelihood functions in fits to histogram is explained further
 in reference 
\begin_inset CommandInset citation
LatexCommand cite
key "baker-cousins"
literal "false"

\end_inset

 and the PDG review on Statistics.
\end_layout

\begin_layout Standard
Consider many binned samples that select different charged current topologies.
 A convenient choice of observables for all the samples are the outgoing
 charged lepton 
\begin_inset Formula $l$
\end_inset

 momentum 
\begin_inset Formula $P_{l}$
\end_inset

 and angle 
\begin_inset Formula $\cos\theta_{l}$
\end_inset

 as measured in the ND.
 Much of this is also documented in TN-220
\begin_inset CommandInset citation
LatexCommand cite
key "Hartz2015"
literal "false"

\end_inset

 where additional details can be found.
 For each 
\begin_inset Formula $\left(P_{l},\cos\theta_{l}\right)$
\end_inset

 analysis bin 
\begin_inset Formula $i=1,2,\ldots,M-1,M$
\end_inset

, the likelihood is given by
\begin_inset Formula 
\begin{equation}
\begin{aligned}\mathcal{L}\left(\vec{N}^{d}\left|\vec{N}^{p}\right.\right) & =\left(\prod_{i=1}^{M}\left(\vec{N}_{i}^{p}\right)^{\vec{N}_{i}^{d}}\frac{e^{-\vec{N}_{i}^{p}}}{\vec{N}_{i}^{d}!}\right)\end{aligned}
\label{eq:likelihoodPoisson}
\end{equation}

\end_inset

where 
\begin_inset Formula $\vec{N}_{i}^{d}$
\end_inset

 is the number of observed data events in the 
\begin_inset Formula $i$
\end_inset

th bin and 
\begin_inset Formula $\vec{N}_{i}^{p}$
\end_inset

 is the number of predicted events as a function of nuisance parameters
 in the 
\begin_inset Formula $i$
\end_inset

th bin.
 One recognizes the likelihood function in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:likelihoodPoisson"
plural "false"
caps "false"
noprefix "false"

\end_inset

 as a Poisson distribution given this is a counting experiment.
 The sets of dependent nuisance parameters, also sometimes called systematics,
 that affect the predicted event rate are
\end_layout

\begin_layout Itemize
cross section (xsec) physics model parameters,
\end_layout

\begin_layout Itemize
neutrino flux, and
\end_layout

\begin_layout Itemize
detector biases and inefficencies.
\end_layout

\begin_layout Standard
Given these three sets of systematics, the number of predicted events is
 described as
\begin_inset Formula 
\begin{equation}
\vec{N}_{i}^{p}\left(\xsec,\flux,\systematics\right)=w_{i}^{\text{POT}}\systematics_{i}^{\text{Det}}\sum_{j=1}^{N_{i}^{\text{MC}}}\left[\sum_{k=1}^{N^{\text{Flux}}}\left(\delta_{j,k}^{\text{Flux}}\flux_{k}\right)\prod_{l=1}^{N^{\text{Syst}}}w_{j,l}\left(\xsec_{l}^{\text{xsec}}\right)\right].\label{eq:n-predicted-events}
\end{equation}

\end_inset

Here 
\begin_inset Formula $w_{i}^{\text{POT}}$
\end_inset

 is the the ratio of of the number of true to simulated (MC) protons on
 target (POT) and 
\begin_inset Formula $N_{i}^{\text{MC}}$
\end_inset

 is the number of events in the 
\begin_inset Formula $i$
\end_inset

th analysis bin.
 The 
\begin_inset Formula $\systematics_{i}^{\text{Det}}$
\end_inset

 parameters are normalization parameters that vary the total number of predicted
 events in the 
\begin_inset Formula $i$
\end_inset

th bin with nominal values based on the detector systematic studies.
 The 
\begin_inset Formula $\flux_{k}$
\end_inset

 parameters, out of a total of 
\begin_inset Formula $N^{\text{Flux}}$
\end_inset

, are flux normalization systematics for each flux bin.
 Since the flux bins are categorized by neutrino flavor, energy, and horn
 (focusing magnet) current, the 
\begin_inset Formula $\delta_{j,k}^{\text{Flux}}$
\end_inset

 term selects the correct flux bin.
 The 
\begin_inset Formula $w_{j,l}\left(\xsec_{l}^{\text{xsec}}\right)$
\end_inset

 parameters are pre-calculated event weight functions for each cross section
 (xsec) model parameter, 
\begin_inset Formula $\xsec_{l}^{\text{xsec}}$
\end_inset

, out of a total of 
\begin_inset Formula $N^{\text{Syst}}$
\end_inset

 cross section systematics.
\end_layout

\begin_layout Standard
In practice one tries to minimization a test statistic which programs like
 MINUIT are designed to find.
 Using the likelihood ratio test theorem, a test statistic can be defined
 using a ratio of two likelihoods
\begin_inset Formula 
\begin{equation}
\Delta\chi_{\text{LLR}}^{2}=-2\log\frac{\mathcal{L}\left(\vec{N}^{d}\left|\vec{N}^{p}\right.\right)}{\mathcal{L}\left(\vec{N}^{d}\left|\vec{N}^{d}\right.\right)}\label{eq:LLHRatio}
\end{equation}

\end_inset

where this test statistic 
\begin_inset Formula $\Delta\chi_{\text{LLR}}^{2}$
\end_inset

 obeys a true chi-squared distribution for asymptotically large statistics.
 Penalty terms from the cross section, flux, and detector systematics are
 included in order to account for their effect.
 The new test statistic for all of ND280, 
\begin_inset Formula $\Delta\chi_{\ND280}^{2}$
\end_inset

, is given by
\begin_inset Formula 
\begin{equation}
\begin{aligned}\Delta\chi_{\ND280}^{2} & =\Delta\chi_{\text{LLR}}^{2}+\Delta\chi_{\text{xsec}}^{2}+\Delta\chi_{\text{Flux}}^{2}+\Delta\chi_{\text{Det}}^{2}\\
 & -2\left(\log\frac{\mathcal{L}\left(\vec{N}^{d}\left|\vec{N}^{p}\right.\right)}{\mathcal{L}\left(\vec{N}^{d}\left|\vec{N}^{d}\right.\right)}+\log\underset{\text{xsec}}{\underbrace{\pi\left(\xsec\right)}}+\log\underset{\text{Flux}}{\underbrace{\pi\left(\flux\right)}}+\log\underset{\text{Det}}{\underbrace{\pi\left(\systematics\right)}}\right)
\end{aligned}
\label{eq:LLHRatioWithPenaltyTerms}
\end{equation}

\end_inset

with each of the priors probability density functions 
\begin_inset Formula $\pi\left(\vec{y}=\xsec,\flux,\systematics\right)$
\end_inset

 are multivariate normal distributions
\begin_inset Formula 
\begin{equation}
\pi(\vec{y})=C_{y}e^{\left(-\frac{1}{2}\Delta\vec{y}\cdot V_{y}^{-1}\cdot\Delta\vec{y}^{T}\right)},\label{eq:nuisancepriorgaussian}
\end{equation}

\end_inset

where 
\begin_inset Formula $\Delta\vec{y}$
\end_inset

 is a vector with the difference between the current/explored and nominal
 set of vector parameters 
\begin_inset Formula $\vec{y}$
\end_inset

, 
\begin_inset Formula $T$
\end_inset

 corresponds to the transpose operator, and the normalization is given by
\begin_inset Formula 
\begin{equation}
C_{y}=\left(\left(2\pi\right)^{k_{y}}\det\left(V_{y}\right)\right)^{-\frac{1}{2}}\label{eq:nuisancepriorgaussiannormalization}
\end{equation}

\end_inset

with 
\begin_inset Formula $V_{y}$
\end_inset

 being the covariance matrix for a vector 
\begin_inset Formula $\vec{y}$
\end_inset

 with 
\begin_inset Formula $k_{y}$
\end_inset

 rows.
 The expanded form of the test statistic 
\begin_inset Formula $\Delta\chi_{\ND280}^{2}$
\end_inset

 is given by
\begin_inset Formula 
\begin{equation}
\begin{aligned}\Delta\chi_{\ND280}^{2} & =2\sum_{i=1}^{M}\left[\vec{N}_{i}^{p}-\vec{N}_{i}^{d}+\vec{N}_{i}^{d}\log\left(\frac{\vec{N}_{i}^{d}}{\vec{N}_{i}^{p}}\right)\right]\\
 & +\Delta\xsec\cdot\left(V_{x}^{-1}\right)\cdot\Delta\xsec^{T}+\Delta\flux\cdot\left(V_{b}^{-1}\right)\cdot\Delta\flux^{T}+\Delta\systematics\cdot\left(V_{d}^{-1}\right)\cdot\Delta\systematics^{T}
\end{aligned}
\label{eq:BANFFDeltaChiSqr}
\end{equation}

\end_inset

where the 
\begin_inset Formula $\cdot$
\end_inset

 is the matrix multiplication operator and the 
\series bold
normalization terms are excluded in the calculation
\series default
.
 Once the global minimum of the test statistic is found, the postfit covariance
 matrix 
\begin_inset Formula $V$
\end_inset

 is calculated as the inverse of the Hessian matrix 
\begin_inset Formula $H$
\end_inset


\begin_inset Formula 
\begin{equation}
V_{i,j}\left(\hat{\vec{y}}\right)=\left(H_{i,j}\right)^{-1}=\left(\left.\frac{\partial^{2}}{\partial y_{i}\partial y_{j}}\left(\Delta\chi_{\ND280}^{2}\right)\right|_{\vec{y}=\hat{\vec{y}}}\right)^{-1}\label{eq:HessianMatrix}
\end{equation}

\end_inset

where 
\begin_inset Formula $y_{i},y_{j}\in\vec{y}$
\end_inset

 and 
\begin_inset Formula $\hat{\vec{y}}$
\end_inset

 is the maximum likelihood estimate for the parmeters 
\begin_inset Formula $\vec{y}$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Flux, Cross Section, and Detector Systematics
\end_layout

\begin_layout Standard
Below is a description for each of the systematics in the BANFF likelihood
 and test statistic penalty terms.
 First is a description of flux parameters, followed by the cross section,
 and finally the detector systematics.
\end_layout

\begin_layout Standard

\series bold
Flux
\series default
: The flux weight is binned as a function of neutrino energy 
\begin_inset Formula $E_{\nu}$
\end_inset

, horn current/polarity (FHC and RHC), and neutrino flavor (
\begin_inset Formula $\numu$
\end_inset

, 
\begin_inset Formula $\numubar$
\end_inset

, 
\begin_inset Formula $\nue$
\end_inset

, and 
\begin_inset Formula $\nuebar$
\end_inset

).
 Each flux bin is a normalization for all events in a set energy range.
 The flux normalization and uncertainty for 
\begin_inset Formula $\numu$
\end_inset

 and 
\begin_inset Formula $\numubar$
\end_inset

 in FHC mode from the 2017 analysis are shown in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:BANFF-ND280-flux"
plural "false"
caps "true"
noprefix "false"

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Figures/Introduction/FluxParametersPrePostFitTN324.png
	lyxscale 50
	width 75text%
	height 49theight%
	keepAspectRatio

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
BANFF ND280 flux 
\begin_inset Formula $\numu$
\end_inset

 and 
\begin_inset Formula $\numubar$
\end_inset

 binning parameters from T2K-TN-324 data post-fit results.
 The uncertainties are extracted from the pre-fit and post-fit covariance
 matrices.
\begin_inset CommandInset label
LatexCommand label
name "fig:BANFF-ND280-flux"

\end_inset


\begin_inset Argument 1
status open

\begin_layout Plain Layout
BANFF ND280 NuMu and ANuMu Flux Binning Parameters
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

.
 Each parameter has a nominal value of one (1).
 A flux bin value of 1.1 indicates that any event in that bin has an additional
 weight of 1.1.
 There are 50 ND and 50 SK parameters with a covariance matrix is shown
 in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:BANFF-pre-fit-flux-covariance"
plural "false"
caps "true"
noprefix "false"

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Figures/Introduction/BANFF_Flux_matrix.png
	lyxscale 50
	width 49text%
	height 49theight%
	keepAspectRatio

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
BANFF pre-fit flux covariance matrix shown with respective detector, horn
 current, and neutrino flavor.
\begin_inset CommandInset label
LatexCommand label
name "fig:BANFF-pre-fit-flux-covariance"

\end_inset


\begin_inset Argument 1
status collapsed

\begin_layout Plain Layout
BANFF Pre-fit Flux Covariance Matrix
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Cross Section
\series default
: There are a number of cross section models and weight functions implemented
 in BANFF.
 The cross section model used in this analysis is the 2017 NIWG parameterization.
 A technical description of the 2017 parameterization is given in T2K-TN-315
\begin_inset CommandInset citation
LatexCommand cite
key "Bolognesi2017"
literal "false"

\end_inset

 and T2K-TN-307
\begin_inset CommandInset citation
LatexCommand cite
key "Mahn2017"
literal "false"

\end_inset

.
 There are model parameters that alter the cross section of CC-0
\begin_inset Formula $\pion$
\end_inset

, CC-1
\begin_inset Formula $\pion$
\end_inset

, final state interactions (FSI), and smaller T2K effects.
 There are 25 cross section parameters as shown in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Cross-section-correlations-prefit"
plural "false"
caps "true"
noprefix "false"

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Figures/Introduction/BANFFXsecPrefitCorrelation.png
	lyxscale 50
	width 49text%
	height 25theight%
	keepAspectRatio

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Cross section parameters pre-fit correlation matrix from the 2017 BANFF
 analysis.
\begin_inset CommandInset label
LatexCommand label
name "fig:Cross-section-correlations-prefit"

\end_inset


\begin_inset Argument 1
status collapsed

\begin_layout Plain Layout
Cross Section Parameters Pre-fit Correlation Matrix
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Bienstock2017"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard

\series bold
Detector Systematics
\series default
: Detector systematics are implemented as normalization changes to event
 kinematics as well as sample migration.
 In order to understand the how the detector systematics affect analysis
 bins, BANFF employs what are called observable normalization parameters,
 also commonly referred to as 
\begin_inset Quotes eld
\end_inset

obsnorms
\begin_inset Quotes erd
\end_inset

.
 Since neutrino interaction events can migrate from sample-to-sample, bin-to-bin
, or both depending on the relevant systematics, numerous toy experiments
 are performed by varying detector systematic model parameters.
 After many toy experiments, usually 2000, all the toy experiments are examined
 together to create a covariance matrix.
 The drawback to this method is that not all detector systematics have Gaussian
 responses to the observables, and so the correlations are not fully accurate.
\end_layout

\begin_layout Standard
Ideally there would be one observable normalization for each analysis bin.
 To reduce the number of fit parameters, a single observable normalization
 parameter can be assigned to multiple analysis bins.
 The number of observable normalization parameters are determined by the
 analyzer by merging the sets of analysis bins.
\end_layout

\end_body
\end_document
